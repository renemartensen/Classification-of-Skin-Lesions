{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../Merge Set Ordered\"\n",
    "iteration = \"iteration_5_1\"\n",
    "model_dir = f'../../models/best_model_{iteration}.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.applications.mobilenet_v3 import preprocess_input\n",
    "\n",
    "\n",
    "# Now import HomemadeDataloader from homemade_dataloader.py\n",
    "from homemade_dataloader import DataloaderFactory\n",
    "\n",
    "\n",
    "batch_size=32\n",
    "dist = [115,115,115,115,115,115,115]\n",
    "print(sum(dist))\n",
    "\n",
    "factory = DataloaderFactory(data_dir, batch_size=batch_size, image_size=(224,224), set_distribution=(70,15,15), class_distribution=dist, preprocess_function=preprocess_input)\n",
    "\n",
    "train_generator, validation_generator, test_generator = factory.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class_names = ['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6']\n",
    "\n",
    "def print_sample_distribution(dataloader, class_names):\n",
    "    \"\"\"Print the distribution of samples per class for each batch and overall.\"\"\"\n",
    "\n",
    "    # Initialize total counts for all classes\n",
    "    total_class_counts = {class_name: 0 for class_name in class_names}\n",
    "\n",
    "    # Per-batch distribution\n",
    "    print(\"\\nDistribution of samples per class for each batch:\")\n",
    "    print(\"Number of batches:\", len(dataloader))\n",
    "    for batch_idx in range(len(dataloader)):\n",
    "        # Fetch batch data\n",
    "        img, labels = dataloader[batch_idx]\n",
    "\n",
    "        # Count occurrences of each class in the batch\n",
    "        batch_class_counts = {class_name: 0 for class_name in class_names}\n",
    "        for label_vector in labels:\n",
    "            class_index = np.argmax(label_vector)  # Convert one-hot to class index\n",
    "            batch_class_counts[class_names[class_index]] += 1\n",
    "            total_class_counts[class_names[class_index]] += 1\n",
    "\n",
    "        # Print batch distribution\n",
    "        print(f\"Batch {batch_idx + 1}:\")\n",
    "        for class_name, count in batch_class_counts.items():\n",
    "            print(f\"  Class '{class_name}': {count} samples\")\n",
    "\n",
    "    # Print overall distribution\n",
    "    print(\"\\nTotal distribution of samples across all batches:\")\n",
    "    for class_name, count in total_class_counts.items():\n",
    "        print(f\"  Class '{class_name}': {count} samples\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage with your defined dataloader\n",
    "print(\"Train Generator Distribution:\", test_generator.isValidation)\n",
    "print_sample_distribution(test_generator, factory.class_names)\n",
    "\n",
    "# print(\"\\nValidation Generator Distribution:\")\n",
    "# print_sample_distribution(validation_generator, factory.class_names)\n",
    "\n",
    "# print(\"\\nTest Generator Distribution:\")\n",
    "# print_sample_distribution(test_generator, factory.class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from custom_model import CustomModel\n",
    "\n",
    "model = CustomModel(number_of_samples=train_generator.samples)\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_epochs(train_generator, validation_generator, epochs=5, checkpoint_path=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unfreeze()\n",
    "model.lr_find(train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_epochs(train_generator, validation_generator, epochs=50, checkpoint_path=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import show_all_plots\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "m = load_model(model_dir)\n",
    "\n",
    "show_all_plots(history, m, test_generator, class_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
